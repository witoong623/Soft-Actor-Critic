{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/witoon/thesis/code/Soft-Actor-Critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/witoon/.venv/ml38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import cycle\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from common.network import ConvBetaVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 512)\n",
    "H, W = image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_base_path = '../vae_weights'\n",
    "models_dict = {\n",
    "#     'b1': (1, 'Carla-v0_town7_outskirts_b1//bvae_town7_epoch(50)-loss(+2.503E+05).pkl'),\n",
    "    'b2': (2, 'Carla-v0_town7_b3_new_tanh_mse_flip/bvae_town7_epoch(100)-loss(+8.586E+04).pkl'),\n",
    "    'b3': (3, 'Carla-v0_town7_b3_new_tanh_mse/bvae_town7_epoch(95)-loss(+8.734E+04).pkl'),\n",
    "#     'b4': (4, 'Carla-v0_town7_outskirts_b4//bvae_town7_epoch(100)-loss(+2.455E+05).pkl')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../vae/eval-images'\n",
    "image_paths = list(map(lambda name: os.path.join(base_path, name), os.listdir(base_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(np_img):\n",
    "    mean = np.array([0.4652, 0.4417, 0.3799])\n",
    "    std = np.array([0.0946, 0.1767, 0.1865])\n",
    "    \n",
    "    new_img = ((np_img * std) + mean) * 255\n",
    "#     new_img = np_img * 255\n",
    "    return new_img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = T.Compose([\n",
    "    T.ToTensor(),\n",
    "#     T.Normalize(mean=[0.4640, 0.4763, 0.3560], std=[0.0941, 0.1722, 0.1883])\n",
    "])\n",
    "\n",
    "def out_tensor_to_np_image(out_tensor):\n",
    "    ''' Convert output tensor to numpy image '''\n",
    "    out_img_np = out_tensor[0].squeeze(dim=0).detach().numpy()\n",
    "    out_img_np = denormalize_image(out_img_np.transpose((1, 2, 0)))\n",
    "    return out_img_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_images = []\n",
    "for key, (beta, weight_name) in models_dict.items():\n",
    "    latent_size = 512\n",
    "    model = ConvBetaVAE(image_size, latent_size=latent_size, beta=beta)\n",
    "    model.load_model(os.path.join(weight_base_path, weight_name))\n",
    "    \n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        pil_img = Image.open(image_path)\n",
    "        np_img = np.array(pil_img)\n",
    "        in_tensor = to_tensor(pil_img)\n",
    "        \n",
    "        out_tensor = model(in_tensor.unsqueeze(dim=0))\n",
    "        out_np_img = out_tensor_to_np_image(out_tensor)\n",
    "        \n",
    "        combined_np_img = np.hstack([np_img, out_np_img])\n",
    "        images.append(combined_np_img)\n",
    "        \n",
    "        pil_img.close()\n",
    "        \n",
    "    reconstruct_images.append(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, images in enumerate(zip(*reconstruct_images), 1):\n",
    "    combined_np_img = np.vstack(images)\n",
    "    combined_pil_img = Image.fromarray(combined_np_img)\n",
    "\n",
    "    draw = ImageDraw.Draw(combined_pil_img)\n",
    "    \n",
    "    pos_y = 0\n",
    "    margin = 10\n",
    "    \n",
    "    for beta in range(2, 4):\n",
    "        text = f'Beta {beta}'\n",
    "        # textwidth, textheight = draw.textsize(text)\n",
    "\n",
    "        pos_y = pos_y + margin\n",
    "        draw.text((10, pos_y), text)\n",
    "        \n",
    "        pos_y += H\n",
    "\n",
    "    combined_pil_img.save(f'../vae/visualize-result/tanh-mse/visualize-result-{num}.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
